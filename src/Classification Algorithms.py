#!/usr/bin/env python
# coding: utf-8

# # Classification Algorithms
# #### By Zachary Austin Ellis & Jose Carlos Gomez-Vazquez
# 
# In this notebook we will implement our own version of the Decision Tree Classifier, Random Forest Classifer, and Naive Bayes Classifier then compare their performance against SciKit-Learn's implementations.
# For these algorithms, the Red Wine Quality dataset provided by Kaggle will be used.
# 
# Source: https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009

# In[1]:


import numpy as np
import pandas as pd

# Used to compare our implementation's performance
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB


# ### Decision Tree Classifier

# In[ ]:





# ### Decision Tree Comparision

# In[ ]:





# ### Random Forest Classifier

# In[ ]:





# ### Random Forest Comparison

# In[ ]:





# ### Naive Bayes Classifier

# In[ ]:





# ### Naive Bayes Comparison

# In[ ]:




